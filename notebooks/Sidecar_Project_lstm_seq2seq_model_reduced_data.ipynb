{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmonch/Sidecar_Project/blob/main/notebooks/Sidecar_Project_lstm_seq2seq_model_reduced_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIb_ydn-kWHQ"
      },
      "source": [
        "# Character-level recurrent sequence-to-sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_YpcXAWkamu"
      },
      "source": [
        "Source: https://keras.io/examples/nlp/lstm_seq2seq/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OJnJM7q1E7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2PGKuBXrkXI",
        "outputId": "c1e10bba-9bf4-4891-c70f-48c1b31b3316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.66)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyZCa2ARkOnm"
      },
      "outputs": [],
      "source": [
        "# nlp packages\n",
        "import re\n",
        "import unicodedata\n",
        "import contractions\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "# progressbar\n",
        "import tqdm\n",
        "\n",
        "# general packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Deeplearing\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# for numpy\n",
        "np.random.seed(seed)\n",
        "# for tenserflow.keras\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "0rHCETaUkDci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flbw5AINq5sc"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848tnZjuk1H1",
        "outputId": "902c78a2-cbc0-433e-a9ec-f63013123934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5SPcebFlCaG"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"gdrive/My Drive/SIDECAR_P/Sidecar_Data_Sample.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ei53wRn11az"
      },
      "outputs": [],
      "source": [
        "top_n= data.Attribute_Business_Name.value_counts()[:100]\n",
        "top_n_df = data[data['Attribute_Business_Name'].map(data['Attribute_Business_Name'].value_counts()).isin(top_n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2va_SMy-C9y",
        "outputId": "6b8c3e39-e552-4e26-e860-059811f4a56b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2099"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(data['Attribute_Business_Name'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEuepDqu-FdZ",
        "outputId": "c1013961-6f61-4c5f-a169-23db69b719ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(top_n_df['Attribute_Business_Name'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezq1kcE977-v",
        "outputId": "c1eb2b3b-96f7-4414-e533-cbefe1243931"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(top_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MpbdWKl2bRb",
        "outputId": "f0031a19-1a13-49bb-dbed-b0c6228b5e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1343"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(top_n_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roK3m0F4_DgC"
      },
      "outputs": [],
      "source": [
        "# if I wanted to run it with only the top 100 hard stop --> .index method\n",
        "# len(data[data['Attribute_Business_Name'].isin(data['Attribute_Business_Name'].value_counts()[:100].index)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "mytXo9EQ2z63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(top_n_df, test_size=0.2, random_state=42, stratify=top_n_df[\"Attribute_Business_Name\"])"
      ],
      "metadata": {
        "id": "w9_sYTcd24Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of Training Set: \" + str(len(train)), \"\\nLength of Test Set: \" + str(len(test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tsmbk1-4CsP",
        "outputId": "568d6741-35eb-4990-a344-bc0960f5e429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Training Set: 1074 \n",
            "Length of Test Set: 269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.Attribute_Business_Name.value_counts(), test.Attribute_Business_Name.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju4AtMjk4CP3",
        "outputId": "b4c474d2-45bf-456f-dd95-bc197e844f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date and time the record was last updated.    56\n",
            "Last modified date                            46\n",
            "Last modified by                              41\n",
            "Last Edited By                                39\n",
            "Valid from                                    30\n",
            "                                              ..\n",
            "Discussion Object Id                           5\n",
            "Sponsor id                                     5\n",
            "Total amount excluding tax                     5\n",
            "Full name for this person                      5\n",
            "Total amount of tax                            5\n",
            "Name: Attribute_Business_Name, Length: 115, dtype: int64 Date and time the record was last updated.                                              14\n",
            "Last modified date                                                                      12\n",
            "Last modified by                                                                        11\n",
            "Last Edited By                                                                          10\n",
            "Valid from                                                                               8\n",
            "                                                                                        ..\n",
            "Description of the item supplied (Usually the stock item name but can be overridden)     1\n",
            "Postal Code                                                                              1\n",
            "visit occurrence id                                                                      1\n",
            "Total amount excluding tax                                                               1\n",
            "Classification attribute id                                                              1\n",
            "Name: Attribute_Business_Name, Length: 115, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddSdDiGMq9fa"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for plotting\n",
        "plt.style.use(\"seaborn\")"
      ],
      "metadata": {
        "id": "hXPTUKpc1xt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIbFhHzNks8Z"
      },
      "outputs": [],
      "source": [
        "# for lstm seq 2 seq model\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3xT7E5Vq_6q"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0qyLJ1HrD-0"
      },
      "source": [
        "### Preprocess and normalize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkZjfRIHrQew"
      },
      "outputs": [],
      "source": [
        "# preprocess and normalize Text\n",
        "\n",
        "# in case text not english\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "# preprocessing\n",
        "def pre_process_text(labels):\n",
        "  norm_docs = []\n",
        "  for string in tqdm.tqdm(labels):\n",
        "    string = string.replace(\"_\", \" \")\n",
        "    string = string.translate(string.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    string = remove_accented_chars(string) \n",
        "    # and inset a space where a number follows a letter et vice versa\n",
        "    string = re.sub(r'(?<=\\d)(?=[^\\d\\s])|(?<=[^\\d\\s])(?=\\d)', ' ', string)\n",
        "    # insert space where an uppercase letter follows a lowercase letter\n",
        "    string = re.sub(r\"(?<![A-Z\\W])(?=[A-Z])\", \" \", string)\n",
        "    string = contractions.fix(string)\n",
        "    # where XXXX number to XXXX number replace - with to IN PROGRESS\n",
        "    string = string.replace(\"-\", \" to \")\n",
        "    # remove special characters or whitespaces\n",
        "    string = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", string, flags=re.I|re.A)\n",
        "    string = string.lower()\n",
        "    string = string.strip()\n",
        "    # string = string.split(\" \")\n",
        "    norm_docs.append(string)\n",
        "  return norm_docs\n",
        "\n",
        "# lemamtization\n",
        "\n",
        "#def spacy_lemmatize_text(text):\n",
        "    #text = nlp(text)\n",
        "    #text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    #return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize the Data"
      ],
      "metadata": {
        "id": "vy26nQqPyPH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lc8634PweXQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the data\n",
        "\n",
        "input_texts = pre_process_text(train[\"Attribute_Technical_Name\"])\n",
        "target_texts = [\"\\t\" + s + \"\\n\" for s in pre_process_text(train[\"Attribute_Business_Name\"])]\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for input_name, target_name in zip(input_texts, target_texts):\n",
        "  for char in input_name:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)\n",
        "  for char in target_name:\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcPJOIlnfFiJ",
        "outputId": "a03844cd-2d3b-42f4-c5e7-d291a4f7abde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1074/1074 [00:00<00:00, 60837.91it/s]\n",
            "100%|██████████| 1074/1074 [00:00<00:00, 60728.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1074\n",
            "Number of unique input tokens: 36\n",
            "Number of unique output tokens: 32\n",
            "Max sequence length for inputs: 36\n",
            "Max sequence length for outputs: 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "oocvFQzSiOL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "  \"accuracy\",\n",
        "  \"sparse_top_k_categorical_accuracy\",\n",
        "  \"sparse_categorical_crossentropy\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "SjCckHvvlOli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", \n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=METRICS\n",
        ")\n",
        "\n",
        "mc = keras.callbacks.ModelCheckpoint(\n",
        "    'my_nmt_model_min_loss.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    mode='min'\n",
        ")\n",
        "    \n",
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[mc, es]\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save(\"lstm_s2s_v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga6z_OvVijMW",
        "outputId": "b1b11b83-5da6-4495-9b64-9eda7756d295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 1.4521 - accuracy: 0.7251\n",
            "Epoch 00001: val_loss improved from inf to 0.89477, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 6s 104ms/step - loss: 1.3541 - accuracy: 0.7385 - val_loss: 0.8948 - val_accuracy: 0.8005\n",
            "Epoch 2/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.8954 - accuracy: 0.8022\n",
            "Epoch 00002: val_loss improved from 0.89477 to 0.87091, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.8935 - accuracy: 0.8024 - val_loss: 0.8709 - val_accuracy: 0.8009\n",
            "Epoch 3/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.8747 - accuracy: 0.8011\n",
            "Epoch 00003: val_loss did not improve from 0.87091\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.8667 - accuracy: 0.8027 - val_loss: 0.8820 - val_accuracy: 0.7995\n",
            "Epoch 4/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.8443 - accuracy: 0.8021\n",
            "Epoch 00004: val_loss improved from 0.87091 to 0.79433, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.8382 - accuracy: 0.8033 - val_loss: 0.7943 - val_accuracy: 0.8010\n",
            "Epoch 5/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.8190 - accuracy: 0.8054\n",
            "Epoch 00005: val_loss improved from 0.79433 to 0.78803, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.8260 - accuracy: 0.8040 - val_loss: 0.7880 - val_accuracy: 0.8018\n",
            "Epoch 6/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.7812 - accuracy: 0.8034\n",
            "Epoch 00006: val_loss improved from 0.78803 to 0.75321, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.7885 - accuracy: 0.8044 - val_loss: 0.7532 - val_accuracy: 0.7998\n",
            "Epoch 7/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.7094 - accuracy: 0.8091\n",
            "Epoch 00007: val_loss improved from 0.75321 to 0.71944, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.7469 - accuracy: 0.8060 - val_loss: 0.7194 - val_accuracy: 0.8011\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.8068\n",
            "Epoch 00008: val_loss did not improve from 0.71944\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.6841 - accuracy: 0.8068 - val_loss: 0.7223 - val_accuracy: 0.8005\n",
            "Epoch 9/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.6767 - accuracy: 0.8075\n",
            "Epoch 00009: val_loss did not improve from 0.71944\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6769 - accuracy: 0.8078 - val_loss: 0.7227 - val_accuracy: 0.8046\n",
            "Epoch 10/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.7094 - accuracy: 0.8109\n",
            "Epoch 00010: val_loss improved from 0.71944 to 0.66765, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.7090 - accuracy: 0.8107 - val_loss: 0.6676 - val_accuracy: 0.8026\n",
            "Epoch 11/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.6593 - accuracy: 0.8108\n",
            "Epoch 00011: val_loss improved from 0.66765 to 0.64977, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.6543 - accuracy: 0.8121 - val_loss: 0.6498 - val_accuracy: 0.8082\n",
            "Epoch 12/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.6359 - accuracy: 0.8132\n",
            "Epoch 00012: val_loss improved from 0.64977 to 0.63804, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.6347 - accuracy: 0.8136 - val_loss: 0.6380 - val_accuracy: 0.8099\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7049 - accuracy: 0.8180\n",
            "Epoch 00013: val_loss improved from 0.63804 to 0.62874, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 0.7049 - accuracy: 0.8180 - val_loss: 0.6287 - val_accuracy: 0.8149\n",
            "Epoch 14/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.6179 - accuracy: 0.8179\n",
            "Epoch 00014: val_loss did not improve from 0.62874\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6074 - accuracy: 0.8206 - val_loss: 0.6295 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.6006 - accuracy: 0.8220\n",
            "Epoch 00015: val_loss improved from 0.62874 to 0.60102, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.5977 - accuracy: 0.8228 - val_loss: 0.6010 - val_accuracy: 0.8204\n",
            "Epoch 16/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.6847 - accuracy: 0.8206\n",
            "Epoch 00016: val_loss improved from 0.60102 to 0.59747, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.6824 - accuracy: 0.8204 - val_loss: 0.5975 - val_accuracy: 0.8205\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.8300\n",
            "Epoch 00017: val_loss improved from 0.59747 to 0.57410, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.5693 - accuracy: 0.8300 - val_loss: 0.5741 - val_accuracy: 0.8234\n",
            "Epoch 18/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.5455 - accuracy: 0.8370\n",
            "Epoch 00018: val_loss did not improve from 0.57410\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.5569 - accuracy: 0.8341 - val_loss: 0.5843 - val_accuracy: 0.8315\n",
            "Epoch 19/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.5449 - accuracy: 0.8376\n",
            "Epoch 00019: val_loss improved from 0.57410 to 0.54323, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.5414 - accuracy: 0.8386 - val_loss: 0.5432 - val_accuracy: 0.8368\n",
            "Epoch 20/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.5290 - accuracy: 0.8420\n",
            "Epoch 00020: val_loss improved from 0.54323 to 0.52523, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.5319 - accuracy: 0.8414 - val_loss: 0.5252 - val_accuracy: 0.8433\n",
            "Epoch 21/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.5034 - accuracy: 0.8509\n",
            "Epoch 00021: val_loss did not improve from 0.52523\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.8503 - val_loss: 0.5729 - val_accuracy: 0.8285\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8515\n",
            "Epoch 00022: val_loss improved from 0.52523 to 0.49835, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.5324 - accuracy: 0.8515 - val_loss: 0.4983 - val_accuracy: 0.8540\n",
            "Epoch 23/100\n",
            "12/14 [========================>.....] - ETA: 0s - loss: 0.4719 - accuracy: 0.8619\n",
            "Epoch 00023: val_loss did not improve from 0.49835\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.4730 - accuracy: 0.8616 - val_loss: 0.4999 - val_accuracy: 0.8534\n",
            "Epoch 24/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.4624 - accuracy: 0.8658\n",
            "Epoch 00024: val_loss improved from 0.49835 to 0.49433, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.4636 - accuracy: 0.8654 - val_loss: 0.4943 - val_accuracy: 0.8532\n",
            "Epoch 25/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.4613 - accuracy: 0.8644\n",
            "Epoch 00025: val_loss improved from 0.49433 to 0.45672, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.4574 - accuracy: 0.8659 - val_loss: 0.4567 - val_accuracy: 0.8693\n",
            "Epoch 26/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.4357 - accuracy: 0.8724\n",
            "Epoch 00026: val_loss did not improve from 0.45672\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4336 - accuracy: 0.8737 - val_loss: 0.4775 - val_accuracy: 0.8597\n",
            "Epoch 27/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.4440 - accuracy: 0.8728\n",
            "Epoch 00027: val_loss improved from 0.45672 to 0.42073, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.4330 - accuracy: 0.8759 - val_loss: 0.4207 - val_accuracy: 0.8803\n",
            "Epoch 28/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.4073 - accuracy: 0.8835\n",
            "Epoch 00028: val_loss did not improve from 0.42073\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.4055 - accuracy: 0.8839 - val_loss: 0.4303 - val_accuracy: 0.8750\n",
            "Epoch 29/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.4082 - accuracy: 0.8837\n",
            "Epoch 00029: val_loss improved from 0.42073 to 0.40516, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.3994 - accuracy: 0.8871 - val_loss: 0.4052 - val_accuracy: 0.8846\n",
            "Epoch 30/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.3676 - accuracy: 0.8965\n",
            "Epoch 00030: val_loss improved from 0.40516 to 0.39295, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.3717 - accuracy: 0.8950 - val_loss: 0.3930 - val_accuracy: 0.8842\n",
            "Epoch 31/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.3542 - accuracy: 0.9014\n",
            "Epoch 00031: val_loss improved from 0.39295 to 0.37201, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.3580 - accuracy: 0.8996 - val_loss: 0.3720 - val_accuracy: 0.8923\n",
            "Epoch 32/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.3535 - accuracy: 0.8994\n",
            "Epoch 00032: val_loss improved from 0.37201 to 0.33873, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.3405 - accuracy: 0.9037 - val_loss: 0.3387 - val_accuracy: 0.9075\n",
            "Epoch 33/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.3354 - accuracy: 0.9070\n",
            "Epoch 00033: val_loss improved from 0.33873 to 0.33251, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.3343 - accuracy: 0.9068 - val_loss: 0.3325 - val_accuracy: 0.9091\n",
            "Epoch 34/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.3144 - accuracy: 0.9148\n",
            "Epoch 00034: val_loss improved from 0.33251 to 0.31900, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.3112 - accuracy: 0.9152 - val_loss: 0.3190 - val_accuracy: 0.9149\n",
            "Epoch 35/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.3019 - accuracy: 0.9176\n",
            "Epoch 00035: val_loss did not improve from 0.31900\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.2982 - accuracy: 0.9185 - val_loss: 0.3510 - val_accuracy: 0.9022\n",
            "Epoch 36/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.2815 - accuracy: 0.9233\n",
            "Epoch 00036: val_loss did not improve from 0.31900\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.2853 - accuracy: 0.9227 - val_loss: 0.3231 - val_accuracy: 0.9088\n",
            "Epoch 37/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.2713 - accuracy: 0.9270\n",
            "Epoch 00037: val_loss improved from 0.31900 to 0.30189, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2699 - accuracy: 0.9270 - val_loss: 0.3019 - val_accuracy: 0.9187\n",
            "Epoch 38/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.2653 - accuracy: 0.9282\n",
            "Epoch 00038: val_loss improved from 0.30189 to 0.26596, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2662 - accuracy: 0.9271 - val_loss: 0.2660 - val_accuracy: 0.9270\n",
            "Epoch 39/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.2524 - accuracy: 0.9312\n",
            "Epoch 00039: val_loss improved from 0.26596 to 0.26547, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2456 - accuracy: 0.9336 - val_loss: 0.2655 - val_accuracy: 0.9280\n",
            "Epoch 40/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.2452 - accuracy: 0.9340\n",
            "Epoch 00040: val_loss improved from 0.26547 to 0.24771, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2363 - accuracy: 0.9366 - val_loss: 0.2477 - val_accuracy: 0.9294\n",
            "Epoch 41/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.2242 - accuracy: 0.9399\n",
            "Epoch 00041: val_loss improved from 0.24771 to 0.23808, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2250 - accuracy: 0.9391 - val_loss: 0.2381 - val_accuracy: 0.9384\n",
            "Epoch 42/100\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 0.2132 - accuracy: 0.9422\n",
            "Epoch 00042: val_loss improved from 0.23808 to 0.22510, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2133 - accuracy: 0.9423 - val_loss: 0.2251 - val_accuracy: 0.9413\n",
            "Epoch 43/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.2044 - accuracy: 0.9459\n",
            "Epoch 00043: val_loss did not improve from 0.22510\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 0.9457 - val_loss: 0.2334 - val_accuracy: 0.9372\n",
            "Epoch 44/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1961 - accuracy: 0.9473\n",
            "Epoch 00044: val_loss improved from 0.22510 to 0.20149, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1918 - accuracy: 0.9484 - val_loss: 0.2015 - val_accuracy: 0.9469\n",
            "Epoch 45/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1806 - accuracy: 0.9527\n",
            "Epoch 00045: val_loss did not improve from 0.20149\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1797 - accuracy: 0.9529 - val_loss: 0.2716 - val_accuracy: 0.9250\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.9363\n",
            "Epoch 00046: val_loss improved from 0.20149 to 0.18986, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2507 - accuracy: 0.9363 - val_loss: 0.1899 - val_accuracy: 0.9509\n",
            "Epoch 47/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1650 - accuracy: 0.9586\n",
            "Epoch 00047: val_loss improved from 0.18986 to 0.17824, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1664 - accuracy: 0.9575 - val_loss: 0.1782 - val_accuracy: 0.9547\n",
            "Epoch 48/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1571 - accuracy: 0.9595\n",
            "Epoch 00048: val_loss did not improve from 0.17824\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1569 - accuracy: 0.9593 - val_loss: 0.1803 - val_accuracy: 0.9527\n",
            "Epoch 49/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1517 - accuracy: 0.9605\n",
            "Epoch 00049: val_loss did not improve from 0.17824\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1518 - accuracy: 0.9605 - val_loss: 0.1826 - val_accuracy: 0.9494\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9590\n",
            "Epoch 00050: val_loss did not improve from 0.17824\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1528 - accuracy: 0.9590 - val_loss: 0.1828 - val_accuracy: 0.9507\n",
            "Epoch 51/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1526 - accuracy: 0.9596\n",
            "Epoch 00051: val_loss improved from 0.17824 to 0.16495, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1467 - accuracy: 0.9612 - val_loss: 0.1650 - val_accuracy: 0.9559\n",
            "Epoch 52/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1372 - accuracy: 0.9634\n",
            "Epoch 00052: val_loss improved from 0.16495 to 0.15979, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1368 - accuracy: 0.9635 - val_loss: 0.1598 - val_accuracy: 0.9564\n",
            "Epoch 53/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1363 - accuracy: 0.9632\n",
            "Epoch 00053: val_loss improved from 0.15979 to 0.15285, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1336 - accuracy: 0.9643 - val_loss: 0.1529 - val_accuracy: 0.9597\n",
            "Epoch 54/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1238 - accuracy: 0.9681\n",
            "Epoch 00054: val_loss did not improve from 0.15285\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1234 - accuracy: 0.9684 - val_loss: 0.1686 - val_accuracy: 0.9530\n",
            "Epoch 55/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1285 - accuracy: 0.9661\n",
            "Epoch 00055: val_loss improved from 0.15285 to 0.13766, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1222 - accuracy: 0.9678 - val_loss: 0.1377 - val_accuracy: 0.9633\n",
            "Epoch 56/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9695\n",
            "Epoch 00056: val_loss improved from 0.13766 to 0.13388, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1132 - accuracy: 0.9708 - val_loss: 0.1339 - val_accuracy: 0.9642\n",
            "Epoch 57/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.1116 - accuracy: 0.9706\n",
            "Epoch 00057: val_loss improved from 0.13388 to 0.12961, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1103 - accuracy: 0.9711 - val_loss: 0.1296 - val_accuracy: 0.9676\n",
            "Epoch 58/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.1037 - accuracy: 0.9734\n",
            "Epoch 00058: val_loss improved from 0.12961 to 0.11918, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1031 - accuracy: 0.9734 - val_loss: 0.1192 - val_accuracy: 0.9690\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9729\n",
            "Epoch 00059: val_loss did not improve from 0.11918\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1023 - accuracy: 0.9729 - val_loss: 0.1296 - val_accuracy: 0.9653\n",
            "Epoch 60/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0911 - accuracy: 0.9768\n",
            "Epoch 00060: val_loss did not improve from 0.11918\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0918 - accuracy: 0.9766 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
            "Epoch 61/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0929 - accuracy: 0.9759\n",
            "Epoch 00061: val_loss improved from 0.11918 to 0.11167, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0914 - accuracy: 0.9765 - val_loss: 0.1117 - val_accuracy: 0.9707\n",
            "Epoch 62/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0869 - accuracy: 0.9775\n",
            "Epoch 00062: val_loss improved from 0.11167 to 0.10409, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0873 - accuracy: 0.9777 - val_loss: 0.1041 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0800 - accuracy: 0.9796\n",
            "Epoch 00063: val_loss did not improve from 0.10409\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0794 - accuracy: 0.9799 - val_loss: 0.1377 - val_accuracy: 0.9625\n",
            "Epoch 64/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0838 - accuracy: 0.9787\n",
            "Epoch 00064: val_loss improved from 0.10409 to 0.09461, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 0.0946 - val_accuracy: 0.9756\n",
            "Epoch 65/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0740 - accuracy: 0.9814\n",
            "Epoch 00065: val_loss did not improve from 0.09461\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9804 - val_loss: 0.1029 - val_accuracy: 0.9729\n",
            "Epoch 66/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0695 - accuracy: 0.9829\n",
            "Epoch 00066: val_loss improved from 0.09461 to 0.09014, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0688 - accuracy: 0.9829 - val_loss: 0.0901 - val_accuracy: 0.9757\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9830\n",
            "Epoch 00067: val_loss improved from 0.09014 to 0.07778, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0685 - accuracy: 0.9830 - val_loss: 0.0778 - val_accuracy: 0.9805\n",
            "Epoch 68/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0605 - accuracy: 0.9847\n",
            "Epoch 00068: val_loss did not improve from 0.07778\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0684 - accuracy: 0.9818 - val_loss: 0.1093 - val_accuracy: 0.9705\n",
            "Epoch 69/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0657 - accuracy: 0.9829\n",
            "Epoch 00069: val_loss did not improve from 0.07778\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0667 - accuracy: 0.9828 - val_loss: 0.0817 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9845\n",
            "Epoch 00070: val_loss did not improve from 0.07778\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0592 - accuracy: 0.9845 - val_loss: 0.1105 - val_accuracy: 0.9678\n",
            "Epoch 71/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0615 - accuracy: 0.9840\n",
            "Epoch 00071: val_loss improved from 0.07778 to 0.07129, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0603 - accuracy: 0.9845 - val_loss: 0.0713 - val_accuracy: 0.9814\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9829\n",
            "Epoch 00072: val_loss did not improve from 0.07129\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 0.9829 - val_loss: 0.0736 - val_accuracy: 0.9809\n",
            "Epoch 73/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0539 - accuracy: 0.9864\n",
            "Epoch 00073: val_loss improved from 0.07129 to 0.06551, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0526 - accuracy: 0.9866 - val_loss: 0.0655 - val_accuracy: 0.9835\n",
            "Epoch 74/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0568 - accuracy: 0.9849\n",
            "Epoch 00074: val_loss did not improve from 0.06551\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0555 - accuracy: 0.9851 - val_loss: 0.0656 - val_accuracy: 0.9829\n",
            "Epoch 75/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0479 - accuracy: 0.9874\n",
            "Epoch 00075: val_loss did not improve from 0.06551\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 0.0718 - val_accuracy: 0.9806\n",
            "Epoch 76/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0506 - accuracy: 0.9862\n",
            "Epoch 00076: val_loss did not improve from 0.06551\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 0.9867 - val_loss: 0.0735 - val_accuracy: 0.9795\n",
            "Epoch 77/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0683 - accuracy: 0.9827\n",
            "Epoch 00077: val_loss improved from 0.06551 to 0.05719, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0635 - accuracy: 0.9837 - val_loss: 0.0572 - val_accuracy: 0.9849\n",
            "Epoch 78/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0434 - accuracy: 0.9885\n",
            "Epoch 00078: val_loss did not improve from 0.05719\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0436 - accuracy: 0.9884 - val_loss: 0.0578 - val_accuracy: 0.9849\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9877\n",
            "Epoch 00079: val_loss did not improve from 0.05719\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.0634 - val_accuracy: 0.9829\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9882\n",
            "Epoch 00080: val_loss did not improve from 0.05719\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 0.0596 - val_accuracy: 0.9846\n",
            "Epoch 81/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0461 - accuracy: 0.9874\n",
            "Epoch 00081: val_loss did not improve from 0.05719\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0459 - accuracy: 0.9876 - val_loss: 0.0608 - val_accuracy: 0.9839\n",
            "Epoch 82/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0463 - accuracy: 0.9873\n",
            "Epoch 00082: val_loss improved from 0.05719 to 0.05651, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0565 - val_accuracy: 0.9844\n",
            "Epoch 83/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0391 - accuracy: 0.9893\n",
            "Epoch 00083: val_loss improved from 0.05651 to 0.05601, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0560 - val_accuracy: 0.9847\n",
            "Epoch 84/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0464 - accuracy: 0.9873\n",
            "Epoch 00084: val_loss improved from 0.05601 to 0.05419, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0457 - accuracy: 0.9873 - val_loss: 0.0542 - val_accuracy: 0.9856\n",
            "Epoch 85/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0362 - accuracy: 0.9897\n",
            "Epoch 00085: val_loss did not improve from 0.05419\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0647 - val_accuracy: 0.9817\n",
            "Epoch 86/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0410 - accuracy: 0.9877\n",
            "Epoch 00086: val_loss improved from 0.05419 to 0.05199, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.0520 - val_accuracy: 0.9862\n",
            "Epoch 87/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0372 - accuracy: 0.9896\n",
            "Epoch 00087: val_loss did not improve from 0.05199\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0542 - val_accuracy: 0.9845\n",
            "Epoch 88/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0377 - accuracy: 0.9893\n",
            "Epoch 00088: val_loss did not improve from 0.05199\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 0.0530 - val_accuracy: 0.9857\n",
            "Epoch 89/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0343 - accuracy: 0.9899\n",
            "Epoch 00089: val_loss improved from 0.05199 to 0.04999, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.0500 - val_accuracy: 0.9862\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9879\n",
            "Epoch 00090: val_loss improved from 0.04999 to 0.04370, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 0.0437 - val_accuracy: 0.9876\n",
            "Epoch 91/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0297 - accuracy: 0.9914\n",
            "Epoch 00091: val_loss did not improve from 0.04370\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.0450 - val_accuracy: 0.9867\n",
            "Epoch 92/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0312 - accuracy: 0.9908\n",
            "Epoch 00092: val_loss did not improve from 0.04370\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.0526 - val_accuracy: 0.9858\n",
            "Epoch 93/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0350 - accuracy: 0.9898\n",
            "Epoch 00093: val_loss did not improve from 0.04370\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
            "Epoch 94/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0322 - accuracy: 0.9906\n",
            "Epoch 00094: val_loss did not improve from 0.04370\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0438 - val_accuracy: 0.9877\n",
            "Epoch 95/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0333 - accuracy: 0.9899\n",
            "Epoch 00095: val_loss improved from 0.04370 to 0.03896, saving model to my_nmt_model_min_loss.h5\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0390 - val_accuracy: 0.9893\n",
            "Epoch 96/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0346 - accuracy: 0.9900\n",
            "Epoch 00096: val_loss did not improve from 0.03896\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0421 - val_accuracy: 0.9880\n",
            "Epoch 97/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0276 - accuracy: 0.9915\n",
            "Epoch 00097: val_loss did not improve from 0.03896\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0397 - val_accuracy: 0.9884\n",
            "Epoch 98/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0296 - accuracy: 0.9910\n",
            "Epoch 00098: val_loss did not improve from 0.03896\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.0451 - val_accuracy: 0.9864\n",
            "Epoch 99/100\n",
            "10/14 [====================>.........] - ETA: 0s - loss: 0.0299 - accuracy: 0.9909\n",
            "Epoch 00099: val_loss did not improve from 0.03896\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 0.0471 - val_accuracy: 0.9863\n",
            "Epoch 100/100\n",
            "11/14 [======================>.......] - ETA: 0s - loss: 0.0283 - accuracy: 0.9918\n",
            "Epoch 00100: val_loss did not improve from 0.03896\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.0401 - val_accuracy: 0.9886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: lstm_s2s_v1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: lstm_s2s_v1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2e9f6c3ed0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2e94286050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "hX1qIK1zkZ27",
        "outputId": "c9a40627-3a49-4bf1-d0ec-808ae87312cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "FGmdIzu0zRmk",
        "outputId": "b034a75a-22ca-4c82-e5c4-4af53025e23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Inference on a sample (n=20) of the Training Data"
      ],
      "metadata": {
        "id": "qc7bLyrk1XS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TisMeH9B0jFG"
      },
      "outputs": [],
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"lstm_s2s_v1\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    # WHY --> to find that vector in the encoded inputs?\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lry6Ba0U0ov2",
        "outputId": "99929b4f-a9d3-4ae6-9129-85d832e02fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: valid to\n",
            "Decoded sentence: valid to\n",
            "\n",
            "True Target sentence: \tvalid to\n",
            "\n",
            "-\n",
            "Input sentence: sys last modified by\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tlast modified by\n",
            "\n",
            "-\n",
            "Input sentence: lineage key\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tlineage key for the data load for this row\n",
            "\n",
            "-\n",
            "Input sentence: modified date\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \tdate and time the record was last updated\n",
            "\n",
            "-\n",
            "Input sentence: classification attribute id\n",
            "Decoded sentence: sme name\n",
            "\n",
            "True Target sentence: \tclassification attribute id\n",
            "\n",
            "-\n",
            "Input sentence: user id\n",
            "Decoded sentence: user id\n",
            "\n",
            "True Target sentence: \tuser identifier\n",
            "\n",
            "-\n",
            "Input sentence: domain id\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \tdomain id\n",
            "\n",
            "-\n",
            "Input sentence: rowguid\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \trowguidcol number uniquely identifying the record used to support a merge replication sample\n",
            "\n",
            "-\n",
            "Input sentence: full name\n",
            "Decoded sentence: first name\n",
            "\n",
            "True Target sentence: \tfull name for this person\n",
            "\n",
            "-\n",
            "Input sentence: last edited by\n",
            "Decoded sentence: last edited by\n",
            "\n",
            "True Target sentence: \tlast edited by\n",
            "\n",
            "-\n",
            "Input sentence: end date\n",
            "Decoded sentence: end date\n",
            "\n",
            "True Target sentence: \tend date\n",
            "\n",
            "-\n",
            "Input sentence: attribute is pk\n",
            "Decoded sentence: is primary key\n",
            "\n",
            "True Target sentence: \tis primary key\n",
            "\n",
            "-\n",
            "Input sentence: city\n",
            "Decoded sentence: phone number\n",
            "\n",
            "True Target sentence: \tcity\n",
            "\n",
            "-\n",
            "Input sentence: total including tax\n",
            "Decoded sentence: sme name\n",
            "\n",
            "True Target sentence: \ttotal amount including tax\n",
            "\n",
            "-\n",
            "Input sentence: application id\n",
            "Decoded sentence: phone number\n",
            "\n",
            "True Target sentence: \tapplication id\n",
            "\n",
            "-\n",
            "Input sentence: attribute business rule\n",
            "Decoded sentence: attribute technical name\n",
            "\n",
            "True Target sentence: \tattribute business rule\n",
            "\n",
            "-\n",
            "Input sentence: product id\n",
            "Decoded sentence: product identification number foreign key to productproduct id\n",
            "\n",
            "True Target sentence: \tproduct identification number foreign key to productproduct id\n",
            "\n",
            "-\n",
            "Input sentence: description\n",
            "Decoded sentence: name of the region\n",
            "\n",
            "True Target sentence: \tdescription\n",
            "\n",
            "-\n",
            "Input sentence: p af 189443\n",
            "Decoded sentence: datetime\n",
            "\n",
            "True Target sentence: \tquantity\n",
            "\n",
            "-\n",
            "Input sentence: asset business name\n",
            "Decoded sentence: business name\n",
            "\n",
            "True Target sentence: \tbusiness name\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n",
        "    print(\"True Target sentence:\", target_texts[seq_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Inference on a sample (n=20) of the Test Data"
      ],
      "metadata": {
        "id": "74MTYZ47gida"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the data\n",
        "\n",
        "input_texts = pre_process_text(test[\"Attribute_Technical_Name\"])\n",
        "target_texts = [\"\\t\" + s + \"\\n\" for s in pre_process_text(test[\"Attribute_Business_Name\"])]\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for input_name, target_name in zip(input_texts, target_texts):\n",
        "  for char in input_name:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)\n",
        "  for char in target_name:\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDhxQDwEgi3e",
        "outputId": "6264b481-afae-49e3-8ef4-a26fbbcc1e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [00:00<00:00, 60751.01it/s]\n",
            "100%|██████████| 269/269 [00:00<00:00, 46268.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 269\n",
            "Number of unique input tokens: 36\n",
            "Number of unique output tokens: 32\n",
            "Max sequence length for inputs: 35\n",
            "Max sequence length for outputs: 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = model.evaluate(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M3DBXhajPDW",
        "outputId": "a82344d4-73ff-4b59-c744-fb3088d15092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 10ms/step - loss: 0.0296 - accuracy: 0.9912\n",
            "Test score: 0.029628992080688477\n",
            "Test accuracy: 0.9912204146385193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n",
        "    print(\"True Target sentence:\", target_texts[seq_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LWml35HiKZP",
        "outputId": "a462d9dc-aba1-459e-9495-e9b69badbde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: asset database\n",
            "Decoded sentence: status id\n",
            "\n",
            "True Target sentence: \tdatabase\n",
            "\n",
            "-\n",
            "Input sentence: attribute business rule\n",
            "Decoded sentence: attribute technical name\n",
            "\n",
            "True Target sentence: \tattribute business rule\n",
            "\n",
            "-\n",
            "Input sentence: domain name\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \tdomain name\n",
            "\n",
            "-\n",
            "Input sentence: visit detail id\n",
            "Decoded sentence: visit detail id\n",
            "\n",
            "True Target sentence: \tvisit detail id\n",
            "\n",
            "-\n",
            "Input sentence: country region name\n",
            "Decoded sentence: phone number\n",
            "\n",
            "True Target sentence: \tcountry region name\n",
            "\n",
            "-\n",
            "Input sentence: valid from\n",
            "Decoded sentence: valid from this date and time\n",
            "\n",
            "True Target sentence: \tvalid from this date and time\n",
            "\n",
            "-\n",
            "Input sentence: total including tax\n",
            "Decoded sentence: is deleted\n",
            "\n",
            "True Target sentence: \ttotal amount including tax\n",
            "\n",
            "-\n",
            "Input sentence: sys is deleted\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tis deleted\n",
            "\n",
            "-\n",
            "Input sentence: attribute business name\n",
            "Decoded sentence: attribute technical name\n",
            "\n",
            "True Target sentence: \tattribute business name\n",
            "\n",
            "-\n",
            "Input sentence: domain name\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \tdomain name\n",
            "\n",
            "-\n",
            "Input sentence: full name\n",
            "Decoded sentence: first name\n",
            "\n",
            "True Target sentence: \tfull name for this person\n",
            "\n",
            "-\n",
            "Input sentence: sys last scanned\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tlast scanned\n",
            "\n",
            "-\n",
            "Input sentence: p af 189359\n",
            "Decoded sentence: datetime\n",
            "\n",
            "True Target sentence: \tunit\n",
            "\n",
            "-\n",
            "Input sentence: sys last modified\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tlast modified date\n",
            "\n",
            "-\n",
            "Input sentence: patient ide\n",
            "Decoded sentence: patient identifier\n",
            "\n",
            "True Target sentence: \tpatient identifier\n",
            "\n",
            "-\n",
            "Input sentence: sys last modified by\n",
            "Decoded sentence: last modified date\n",
            "\n",
            "True Target sentence: \tlast modified by\n",
            "\n",
            "-\n",
            "Input sentence: sourcesystem cd\n",
            "Decoded sentence: phone number\n",
            "\n",
            "True Target sentence: \tsource system code\n",
            "\n",
            "-\n",
            "Input sentence: domain status id\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \tstatus id\n",
            "\n",
            "-\n",
            "Input sentence: attribute status id\n",
            "Decoded sentence: status id\n",
            "\n",
            "True Target sentence: \tstatus id\n",
            "\n",
            "-\n",
            "Input sentence: rowguid\n",
            "Decoded sentence: date and time the record was last updated\n",
            "\n",
            "True Target sentence: \trowguidcol number uniquely identifying the record used to support a merge replication sample\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Sidecar_Project_lstm_seq2seq_model_reduced_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPG8cBHULG0wzjjUB/EfTXa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}