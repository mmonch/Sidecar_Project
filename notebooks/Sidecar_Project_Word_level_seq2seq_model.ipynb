{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmonch/Sidecar_Project/blob/main/notebooks/Sidecar_Project_Word_level_seq2seq_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "TcCMqbiVYnFl"
      },
      "source": [
        "<a id='Q0'></a>\n",
        "<center><a target=\"_blank\" href=\"https://sit.academy/\"><img src=\"https://drive.google.com/uc?id=1z0U84GYqhbWWpCenFajh8_8XFRGyOc3U\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "<center> <h1> Notebook 4: Word-level Seq2Seq RNN Model </h1> </center>\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "<center><h4>Marlies Monch, SIT Academy, 2022</h4></center>\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "<div style=\"background:#EEEDF5;border-top:0.1cm solid #EF475B;border-bottom:0.1cm solid #EF475B;\">\n",
        "    <div style=\"margin-left: 0.5cm;margin-top: 0.5cm;margin-bottom: 0.5cm;color:#303030\">\n",
        "        <p><strong>Goal:</strong> Run a word-level seq2seq model (RNN) on the attribute technical names to match the attribute business names</p>\n",
        "        <strong> Outline:</strong>\n",
        "        <a id='P0' name=\"P0\"></a>\n",
        "        <ol>\n",
        "            <li> <a style=\"color:#303030\" href='#I'>Introduction </a> </li>\n",
        "            <li> <a style=\"color:#303030\" href='#SU'>Set up</a></li>\n",
        "            <li> <a style=\"color:#303030\" href='#DP'>Data Preparation</a></li>\n",
        "            <li> <a style=\"color:#303030\" href='#CT'>Compile and Train the Model</a></li>\n",
        "            <li> <a style=\"color:#303030\" href='#TP'>Test Data Performance</a></li>\n",
        "            <li> <a style=\"color:#303030\" href='#CL'>Conclusion</a></li>\n",
        "        </ol>\n",
        "        <strong>Keywords:</strong> data preprocessing, seq2seq, NLP, Sidecar attribute names, word-level.\n",
        "    </div>\n",
        "</div>\n",
        "</nav>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86cmQzAYnFn"
      },
      "source": [
        "<a id='I' name=\"I\"></a>\n",
        "## [Introduction](#P0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7o-oAEuYnFn"
      },
      "source": [
        "Sources:\n",
        "\n",
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n",
        "\n",
        "https://loeb.nyc/blog/data-science-word-expander\n",
        "\n",
        "https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0\n",
        "\n",
        "https://towardsdatascience.com/guide-to-fine-tuning-text-generation-models-gpt-2-gpt-neo-and-t5-dc5de6b3bc5e\n",
        "\n",
        "https://www.machinecurve.com/index.php/2020/12/29/differences-between-autoregressive-autoencoding-and-sequence-to-sequence-models-in-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XENd8ZgPYnFo"
      },
      "source": [
        "<a id='SU' name=\"SU\"></a>\n",
        "## [Set up](#P0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUSprQRpYnFo"
      },
      "source": [
        "###Package Installations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nb_black\n",
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n",
        "!pip install --upgrade IPython"
      ],
      "metadata": {
        "id": "nuw3F8xNcWNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "3a1f42ce-30df-4136-9cb2-3930d2a41761"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nb_black in /usr/local/lib/python3.7/dist-packages (1.0.7)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from nb_black) (7.32.0)\n",
            "Requirement already satisfied: black>='19.3' in /usr/local/lib/python3.7/dist-packages (from nb_black) (22.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (0.4.3)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (2.5.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (3.10.0.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (8.0.4)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (1.5.2)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb_black) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black>='19.3'->nb_black) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black>='19.3'->nb_black) (3.7.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (3.0.28)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (0.7.5)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (0.1.3)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (0.18.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->nb_black) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython->nb_black) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython->nb_black) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb_black) (0.2.5)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.66)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (7.32.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from IPython) (0.1.3)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython) (3.0.28)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from IPython) (0.18.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->IPython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 8;\n",
              "                var nbb_unformatted_code = \"!pip install nb_black\\n!pip install contractions\\n!pip install textsearch\\n!pip install tqdm\\n!pip install --upgrade IPython\";\n",
              "                var nbb_formatted_code = \"!pip install nb_black\\n!pip install contractions\\n!pip install textsearch\\n!pip install tqdm\\n!pip install --upgrade IPython\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magics"
      ],
      "metadata": {
        "id": "AaUQFIX1jUkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "axuCywGJYnFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "85f55541-a4bf-4281-f58e-b358c29d3523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "The nb_black extension is already loaded. To reload it, use:\n",
            "  %reload_ext nb_black\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 9;\n",
              "                var nbb_unformatted_code = \"# auto reload packages and modules when they are modified\\n%load_ext autoreload\\n%autoreload 2\\n# draw matplotlib plots in line\\n%matplotlib inline\\n# enforce PEP 8 code on jupyter lab ...\\n#%load_ext lab_black\\n# ... or jupyter notebook\\n%load_ext nb_black\";\n",
              "                var nbb_formatted_code = \"# auto reload packages and modules when they are modified\\n%load_ext autoreload\\n%autoreload 2\\n# draw matplotlib plots in line\\n%matplotlib inline\\n# enforce PEP 8 code on jupyter lab ...\\n#%load_ext lab_black\\n# ... or jupyter notebook\\n%load_ext nb_black\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# auto reload packages and modules when they are modified\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# draw matplotlib plots in line\n",
        "%matplotlib inline\n",
        "# enforce PEP 8 code on jupyter lab ...\n",
        "#%load_ext lab_black\n",
        "# ... or jupyter notebook\n",
        "%load_ext nb_black"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwYad_o4YnFp"
      },
      "source": [
        "### Package Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-07T16:56:09.469904Z",
          "start_time": "2019-01-07T16:56:07.858398Z"
        },
        "id": "xX5dlhbTYnFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0fc32c47-73f3-40bb-8c47-3d82430530f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 10;\n",
              "                var nbb_unformatted_code = \"import nltk\\nimport pandas as pd\\nimport numpy as np\\nimport tqdm\\nimport tensorflow as tf\\nimport unicodedata\\nimport re\\nimport contractions\\nimport sklearn\\nfrom tensorflow.keras import layers\\nfrom tensorflow import keras\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Flatten\\nfrom tensorflow.keras.layers import Conv1D\\nfrom tensorflow.keras.layers import MaxPooling1D\\nfrom tensorflow.keras.layers import Embedding\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing import sequence\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.layers import TextVectorization\\n\\n# from nltk get \\\"punkt\\\"\\nnltk.download('punkt')\";\n",
              "                var nbb_formatted_code = \"import nltk\\nimport pandas as pd\\nimport numpy as np\\nimport tqdm\\nimport tensorflow as tf\\nimport unicodedata\\nimport re\\nimport contractions\\nimport sklearn\\nfrom tensorflow.keras import layers\\nfrom tensorflow import keras\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Flatten\\nfrom tensorflow.keras.layers import Conv1D\\nfrom tensorflow.keras.layers import MaxPooling1D\\nfrom tensorflow.keras.layers import Embedding\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing import sequence\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.layers import TextVectorization\\n\\n# from nltk get \\\"punkt\\\"\\nnltk.download(\\\"punkt\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import re\n",
        "import contractions\n",
        "import sklearn\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# from nltk get \"punkt\"\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# for numpy\n",
        "np.random.seed(seed)\n",
        "# for tenserflow.keras\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9yZ3hzT4jemL",
        "outputId": "0951a0c2-362b-487c-ada4-7cb3928dc0b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 11;\n",
              "                var nbb_unformatted_code = \"# fix random seed for reproducibility\\nseed = 42\\n\\n# for numpy\\nnp.random.seed(seed)\\n# for tenserflow.keras\\ntf.random.set_seed(seed)\";\n",
              "                var nbb_formatted_code = \"# fix random seed for reproducibility\\nseed = 42\\n\\n# for numpy\\nnp.random.seed(seed)\\n# for tenserflow.keras\\ntf.random.set_seed(seed)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIHEoLBYnFr"
      },
      "source": [
        "### User-Dependent Variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_6RoD2gWdVhW",
        "outputId": "4097347b-2e47-43a7-e002-0ef676f2d95a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 12;\n",
              "                var nbb_unformatted_code = \"from google.colab import drive\\ndrive.mount('/content/gdrive')\";\n",
              "                var nbb_formatted_code = \"from google.colab import drive\\n\\ndrive.mount(\\\"/content/gdrive\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"gdrive/My Drive/SIDECAR_P/data/Sidecar_Data_Sample.csv\")"
      ],
      "metadata": {
        "id": "nkSRl9EVd5E2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e99d7d49-ebe1-4c67-e36e-55fcf3523c77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 13;\n",
              "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"gdrive/My Drive/SIDECAR_P/data/Sidecar_Data_Sample.csv\\\")\";\n",
              "                var nbb_formatted_code = \"data = pd.read_csv(\\\"gdrive/My Drive/SIDECAR_P/data/Sidecar_Data_Sample.csv\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lnhzDc9YnFr"
      },
      "source": [
        "<a id='DP'></a>\n",
        "## [Data Preparation](#P0)\n",
        "\n",
        "First we will remove very abstract rows of data that would confuse the model. Ten we will pre-process the text by stripping underscores, excess white spaces etc. Next, we create a Dataframe paring each Attribute Technical Name with it's respective Attribute Business Name. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Pre-Processing"
      ],
      "metadata": {
        "id": "FukUnrl3kkTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove P_AF18XXXX values for better performance\n",
        "data_no_paf = data[data['Attribute_Technical_Name'].str.contains(\"P_AF\")==False]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hfHS39_rCSaO",
        "outputId": "f47b7b96-b0b5-46a6-d786-0dc95c1a108d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 14;\n",
              "                var nbb_unformatted_code = \"# remove P_AF18XXXX values for better performance\\ndata_no_paf = data[data['Attribute_Technical_Name'].str.contains(\\\"P_AF\\\")==False]\";\n",
              "                var nbb_formatted_code = \"# remove P_AF18XXXX values for better performance\\ndata_no_paf = data[data[\\\"Attribute_Technical_Name\\\"].str.contains(\\\"P_AF\\\") == False]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess and normalize Text\n",
        "\n",
        "# in case text not english\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "# preprocessing\n",
        "def pre_process_text(labels):\n",
        "  norm_docs = []\n",
        "  for string in tqdm.tqdm(labels):\n",
        "    string = string.replace(\"_\", \" \")\n",
        "    string = string.translate(string.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    string = remove_accented_chars(string) \n",
        "    # and inset a space where a number follows a letter et vice versa\n",
        "    string = re.sub(r'(?<=\\d)(?=[^\\d\\s])|(?<=[^\\d\\s])(?=\\d)', ' ', string)\n",
        "    # insert space where an uppercase letter follows a lowercase letter\n",
        "    string = re.sub(r\"(?<![A-Z\\W])(?=[A-Z])\", \" \", string)\n",
        "    string = contractions.fix(string)\n",
        "    string = string.replace(\"-\", \" to \")\n",
        "    # remove special characters or whitespaces\n",
        "    string = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", string, flags=re.I|re.A)\n",
        "    string = string.lower()\n",
        "    string = string.strip()\n",
        "    # no splitting needed for this RNN\n",
        "    # string = string.split(\" \")\n",
        "    norm_docs.append(string)\n",
        "  return norm_docs"
      ],
      "metadata": {
        "id": "P-eahSgLaZIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e6b2a50d-8566-4757-c4f7-b795d0c9843e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 15;\n",
              "                var nbb_unformatted_code = \"# preprocess and normalize Text\\n\\n# in case text not english\\ndef remove_accented_chars(text):\\n  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\\n  return text\\n\\n# preprocessing\\ndef pre_process_text(labels):\\n  norm_docs = []\\n  for string in tqdm.tqdm(labels):\\n    string = string.replace(\\\"_\\\", \\\" \\\")\\n    string = string.translate(string.maketrans(\\\"\\\\n\\\\t\\\\r\\\", \\\"   \\\"))\\n    string = remove_accented_chars(string) \\n    # and inset a space where a number follows a letter et vice versa\\n    string = re.sub(r'(?<=\\\\d)(?=[^\\\\d\\\\s])|(?<=[^\\\\d\\\\s])(?=\\\\d)', ' ', string)\\n    # insert space where an uppercase letter follows a lowercase letter\\n    string = re.sub(r\\\"(?<![A-Z\\\\W])(?=[A-Z])\\\", \\\" \\\", string)\\n    string = contractions.fix(string)\\n    string = string.replace(\\\"-\\\", \\\" to \\\")\\n    # remove special characters or whitespaces\\n    string = re.sub(r\\\"[^a-zA-Z0-9\\\\s]\\\", \\\"\\\", string, flags=re.I|re.A)\\n    string = string.lower()\\n    string = string.strip()\\n    # no splitting needed for this RNN\\n    # string = string.split(\\\" \\\")\\n    norm_docs.append(string)\\n  return norm_docs\";\n",
              "                var nbb_formatted_code = \"# preprocess and normalize Text\\n\\n# in case text not english\\ndef remove_accented_chars(text):\\n    text = (\\n        unicodedata.normalize(\\\"NFKD\\\", text)\\n        .encode(\\\"ascii\\\", \\\"ignore\\\")\\n        .decode(\\\"utf-8\\\", \\\"ignore\\\")\\n    )\\n    return text\\n\\n\\n# preprocessing\\ndef pre_process_text(labels):\\n    norm_docs = []\\n    for string in tqdm.tqdm(labels):\\n        string = string.replace(\\\"_\\\", \\\" \\\")\\n        string = string.translate(string.maketrans(\\\"\\\\n\\\\t\\\\r\\\", \\\"   \\\"))\\n        string = remove_accented_chars(string)\\n        # and inset a space where a number follows a letter et vice versa\\n        string = re.sub(r\\\"(?<=\\\\d)(?=[^\\\\d\\\\s])|(?<=[^\\\\d\\\\s])(?=\\\\d)\\\", \\\" \\\", string)\\n        # insert space where an uppercase letter follows a lowercase letter\\n        string = re.sub(r\\\"(?<![A-Z\\\\W])(?=[A-Z])\\\", \\\" \\\", string)\\n        string = contractions.fix(string)\\n        string = string.replace(\\\"-\\\", \\\" to \\\")\\n        # remove special characters or whitespaces\\n        string = re.sub(r\\\"[^a-zA-Z0-9\\\\s]\\\", \\\"\\\", string, flags=re.I | re.A)\\n        string = string.lower()\\n        string = string.strip()\\n        # no splitting needed for this RNN\\n        # string = string.split(\\\" \\\")\\n        norm_docs.append(string)\\n    return norm_docs\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep_tech = pre_process_text(data_no_paf[\"Attribute_Technical_Name\"])\n"
      ],
      "metadata": {
        "id": "a1UVUjAZaZQd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0b46932-d537-4eac-a3d8-6a6a3a91a902"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3941/3941 [00:00<00:00, 55763.50it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 16;\n",
              "                var nbb_unformatted_code = \"prep_tech = pre_process_text(data_no_paf[\\\"Attribute_Technical_Name\\\"])\";\n",
              "                var nbb_formatted_code = \"prep_tech = pre_process_text(data_no_paf[\\\"Attribute_Technical_Name\\\"])\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep_business = pre_process_text(data_no_paf[\"Attribute_Business_Name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OEIVuKgju_FF",
        "outputId": "3d94721c-b7ab-4669-df16-9e41181e6a35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3941/3941 [00:00<00:00, 49707.26it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 17;\n",
              "                var nbb_unformatted_code = \"prep_business = pre_process_text(data_no_paf[\\\"Attribute_Business_Name\\\"])\";\n",
              "                var nbb_formatted_code = \"prep_business = pre_process_text(data_no_paf[\\\"Attribute_Business_Name\\\"])\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add start and end tags for business labels so that they can be read by the RNN model\n",
        "prep_business = [\"[start] \" + s + \" [end]\" for s in prep_business]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4If296V9aWqq",
        "outputId": "070cbe97-47c4-4abe-acc6-aaac793890c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 18;\n",
              "                var nbb_unformatted_code = \"# add start and end tags for business labels so that they can be read by the RNN model\\nprep_business = [\\\"[start] \\\" + s + \\\" [end]\\\" for s in prep_business]\";\n",
              "                var nbb_formatted_code = \"# add start and end tags for business labels so that they can be read by the RNN model\\nprep_business = [\\\"[start] \\\" + s + \\\" [end]\\\" for s in prep_business]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep_business"
      ],
      "metadata": {
        "id": "D4DTmx5YbIp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training Dataset"
      ],
      "metadata": {
        "id": "seTft-KPlsjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parse text into text pairs\n",
        "tech = pd.DataFrame(prep_tech, columns =[\"tech_name\"], dtype=\"string\")\n",
        "busi = pd.DataFrame(prep_business, columns =[\"busi_name\"], dtype=\"string\")\n",
        "\n",
        "attribute_df = pd.concat([tech,busi], axis=1)\n",
        "attribute_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cF9H7edVvLgB",
        "outputId": "2d4fd784-8510-49cf-90f8-d09e192cbc36"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5226211a-9a74-464a-b330-ee4ee02b07c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tech_name</th>\n",
              "      <th>busi_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>[start] technical id of the patient [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gndr cd</td>\n",
              "      <td>[start] gender code [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>livg arngmnt cd</td>\n",
              "      <td>[start] living arrangement [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mrtl stus cd</td>\n",
              "      <td>[start] marital status code [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ocupatn cd</td>\n",
              "      <td>[start] occupation code [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3936</th>\n",
              "      <td>config asset list data source</td>\n",
              "      <td>[start] config asset list data source [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3937</th>\n",
              "      <td>attribute sample data</td>\n",
              "      <td>[start] attribute sample data [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3938</th>\n",
              "      <td>property is dq</td>\n",
              "      <td>[start] property is dq [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3939</th>\n",
              "      <td>property dq calculation</td>\n",
              "      <td>[start] property dq calculation [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3940</th>\n",
              "      <td>property dq output format</td>\n",
              "      <td>[start] property dq output format [end]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3941 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5226211a-9a74-464a-b330-ee4ee02b07c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5226211a-9a74-464a-b330-ee4ee02b07c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5226211a-9a74-464a-b330-ee4ee02b07c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          tech_name                                    busi_name\n",
              "0                                id    [start] technical id of the patient [end]\n",
              "1                           gndr cd                    [start] gender code [end]\n",
              "2                   livg arngmnt cd             [start] living arrangement [end]\n",
              "3                      mrtl stus cd            [start] marital status code [end]\n",
              "4                        ocupatn cd                [start] occupation code [end]\n",
              "...                             ...                                          ...\n",
              "3936  config asset list data source  [start] config asset list data source [end]\n",
              "3937          attribute sample data          [start] attribute sample data [end]\n",
              "3938                 property is dq                 [start] property is dq [end]\n",
              "3939        property dq calculation        [start] property dq calculation [end]\n",
              "3940      property dq output format      [start] property dq output format [end]\n",
              "\n",
              "[3941 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 20;\n",
              "                var nbb_unformatted_code = \"# parse text into text pairs\\ntech = pd.DataFrame(prep_tech, columns =[\\\"tech_name\\\"], dtype=\\\"string\\\")\\nbusi = pd.DataFrame(prep_business, columns =[\\\"busi_name\\\"], dtype=\\\"string\\\")\\n\\nattribute_df = pd.concat([tech,busi], axis=1)\\nattribute_df\";\n",
              "                var nbb_formatted_code = \"# parse text into text pairs\\ntech = pd.DataFrame(prep_tech, columns=[\\\"tech_name\\\"], dtype=\\\"string\\\")\\nbusi = pd.DataFrame(prep_business, columns=[\\\"busi_name\\\"], dtype=\\\"string\\\")\\n\\nattribute_df = pd.concat([tech, busi], axis=1)\\nattribute_df\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lGwmvOlimh22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "-en3yCmvl_Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle and define labels\n",
        "attribute_df = attribute_df.sample(frac=1, random_state=42)\n",
        "# X = attribute_df[\"tech_name\"]\n",
        "# Y = attribute_df[\"busi_name\"]\n",
        "\n",
        "# train test split\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, train_size=None, random_state=42)\n",
        "\n",
        "num_val_samples = int(0.15 * len(attribute_df))\n",
        "num_train_samples = len(attribute_df) - 2 * num_val_samples\n",
        "train_pairs = attribute_df[:num_train_samples]\n",
        "val_pairs = attribute_df[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = attribute_df[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(attribute_df)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Ry8ijBWi7alm",
        "outputId": "c5b57910-9d9d-4d52-a865-c480aa9f2a75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3941 total pairs\n",
            "2759 training pairs\n",
            "591 validation pairs\n",
            "591 test pairs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 21;\n",
              "                var nbb_unformatted_code = \"# shuffle and define labels\\nattribute_df = attribute_df.sample(frac=1, random_state=42)\\n# X = attribute_df[\\\"tech_name\\\"]\\n# Y = attribute_df[\\\"busi_name\\\"]\\n\\n# train test split\\n# x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, train_size=None, random_state=42)\\n\\nnum_val_samples = int(0.15 * len(attribute_df))\\nnum_train_samples = len(attribute_df) - 2 * num_val_samples\\ntrain_pairs = attribute_df[:num_train_samples]\\nval_pairs = attribute_df[num_train_samples : num_train_samples + num_val_samples]\\ntest_pairs = attribute_df[num_train_samples + num_val_samples :]\\n\\nprint(f\\\"{len(attribute_df)} total pairs\\\")\\nprint(f\\\"{len(train_pairs)} training pairs\\\")\\nprint(f\\\"{len(val_pairs)} validation pairs\\\")\\nprint(f\\\"{len(test_pairs)} test pairs\\\")\";\n",
              "                var nbb_formatted_code = \"# shuffle and define labels\\nattribute_df = attribute_df.sample(frac=1, random_state=42)\\n# X = attribute_df[\\\"tech_name\\\"]\\n# Y = attribute_df[\\\"busi_name\\\"]\\n\\n# train test split\\n# x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, train_size=None, random_state=42)\\n\\nnum_val_samples = int(0.15 * len(attribute_df))\\nnum_train_samples = len(attribute_df) - 2 * num_val_samples\\ntrain_pairs = attribute_df[:num_train_samples]\\nval_pairs = attribute_df[num_train_samples : num_train_samples + num_val_samples]\\ntest_pairs = attribute_df[num_train_samples + num_val_samples :]\\n\\nprint(f\\\"{len(attribute_df)} total pairs\\\")\\nprint(f\\\"{len(train_pairs)} training pairs\\\")\\nprint(f\\\"{len(val_pairs)} validation pairs\\\")\\nprint(f\\\"{len(test_pairs)} test pairs\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization"
      ],
      "metadata": {
        "id": "JFkQ0Pc8mDJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "tech_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "busi_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        ")\n",
        "train_tech_texts = [pair[0] for pair in train_pairs]\n",
        "train_busi_texts = [pair[1] for pair in train_pairs]\n",
        "tech_vectorization.adapt(train_tech_texts)\n",
        "busi_vectorization.adapt(train_busi_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Wh_4eaKNx2Gf",
        "outputId": "7c1b853f-4cde-4776-a719-7024f728d7dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 22;\n",
              "                var nbb_unformatted_code = \"# Vectorize the data\\n\\nvocab_size = 15000\\nsequence_length = 20\\nbatch_size = 64\\n\\ntech_vectorization = TextVectorization(\\n    max_tokens=vocab_size, output_mode=\\\"int\\\", output_sequence_length=sequence_length,\\n)\\nbusi_vectorization = TextVectorization(\\n    max_tokens=vocab_size,\\n    output_mode=\\\"int\\\",\\n    output_sequence_length=sequence_length + 1,\\n)\\ntrain_tech_texts = [pair[0] for pair in train_pairs]\\ntrain_busi_texts = [pair[1] for pair in train_pairs]\\ntech_vectorization.adapt(train_tech_texts)\\nbusi_vectorization.adapt(train_busi_texts)\";\n",
              "                var nbb_formatted_code = \"# Vectorize the data\\n\\nvocab_size = 15000\\nsequence_length = 20\\nbatch_size = 64\\n\\ntech_vectorization = TextVectorization(\\n    max_tokens=vocab_size,\\n    output_mode=\\\"int\\\",\\n    output_sequence_length=sequence_length,\\n)\\nbusi_vectorization = TextVectorization(\\n    max_tokens=vocab_size,\\n    output_mode=\\\"int\\\",\\n    output_sequence_length=sequence_length + 1,\\n)\\ntrain_tech_texts = [pair[0] for pair in train_pairs]\\ntrain_busi_texts = [pair[1] for pair in train_pairs]\\ntech_vectorization.adapt(train_tech_texts)\\nbusi_vectorization.adapt(train_busi_texts)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs = train_pairs.to_records(index=False)\n",
        "train_pairs = list(train_pairs)\n"
      ],
      "metadata": {
        "id": "8CLdzaZm3DHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pairs = val_pairs.to_records(index=False)\n",
        "val_pairs = list(val_pairs)"
      ],
      "metadata": {
        "id": "Xce0p0Ad4YzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pairs"
      ],
      "metadata": {
        "id": "OXMOfCZu5U4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to format datasets and vectorize them\n",
        "def format_dataset(tech, busi):\n",
        "    tech = tech_vectorization(tech)\n",
        "    busi = busi_vectorization(busi)\n",
        "    return ({\"encoder_inputs\": tech, \"decoder_inputs\": busi[:, :-1],}, busi[:, 1:])\n",
        "\n",
        "# function to make dataset pairs and shuffle the data\n",
        "def make_dataset(pairs):\n",
        "    tech_texts, busi_texts = zip(*pairs)\n",
        "    tech_texts = list(tech_texts)\n",
        "    busi_texts = list(busi_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((tech_texts, busi_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e68eSTZ1Gd8m",
        "outputId": "8f11b705-94ad-473b-b8fa-f53ccb195d9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 26;\n",
              "                var nbb_unformatted_code = \"def format_dataset(tech, busi):\\n    tech = tech_vectorization(tech)\\n    busi = busi_vectorization(busi)\\n    return ({\\\"encoder_inputs\\\": tech, \\\"decoder_inputs\\\": busi[:, :-1],}, busi[:, 1:])\\n\\n\\ndef make_dataset(pairs):\\n    tech_texts, busi_texts = zip(*pairs)\\n    tech_texts = list(tech_texts)\\n    busi_texts = list(busi_texts)\\n    dataset = tf.data.Dataset.from_tensor_slices((tech_texts, busi_texts))\\n    dataset = dataset.batch(batch_size)\\n    dataset = dataset.map(format_dataset)\\n    return dataset.shuffle(2048).prefetch(16).cache()\\n\\n\\ntrain_ds = make_dataset(train_pairs)\\nval_ds = make_dataset(val_pairs)\";\n",
              "                var nbb_formatted_code = \"def format_dataset(tech, busi):\\n    tech = tech_vectorization(tech)\\n    busi = busi_vectorization(busi)\\n    return (\\n        {\\n            \\\"encoder_inputs\\\": tech,\\n            \\\"decoder_inputs\\\": busi[:, :-1],\\n        },\\n        busi[:, 1:],\\n    )\\n\\n\\ndef make_dataset(pairs):\\n    tech_texts, busi_texts = zip(*pairs)\\n    tech_texts = list(tech_texts)\\n    busi_texts = list(busi_texts)\\n    dataset = tf.data.Dataset.from_tensor_slices((tech_texts, busi_texts))\\n    dataset = dataset.batch(batch_size)\\n    dataset = dataset.map(format_dataset)\\n    return dataset.shuffle(2048).prefetch(16).cache()\\n\\n\\ntrain_ds = make_dataset(train_pairs)\\nval_ds = make_dataset(val_pairs)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder and decoder input shapes\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "E5j1nk2M7w39",
        "outputId": "3c61b11f-94f2-43d9-aa60-91673ecb6265"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 27;\n",
              "                var nbb_unformatted_code = \"for inputs, targets in train_ds.take(1):\\n    print(f'inputs[\\\"encoder_inputs\\\"].shape: {inputs[\\\"encoder_inputs\\\"].shape}')\\n    print(f'inputs[\\\"decoder_inputs\\\"].shape: {inputs[\\\"decoder_inputs\\\"].shape}')\\n    print(f\\\"targets.shape: {targets.shape}\\\")\";\n",
              "                var nbb_formatted_code = \"for inputs, targets in train_ds.take(1):\\n    print(f'inputs[\\\"encoder_inputs\\\"].shape: {inputs[\\\"encoder_inputs\\\"].shape}')\\n    print(f'inputs[\\\"decoder_inputs\\\"].shape: {inputs[\\\"decoder_inputs\\\"].shape}')\\n    print(f\\\"targets.shape: {targets.shape}\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='CT'></a>\n",
        "## [Compile and Train the Model](#P0)"
      ],
      "metadata": {
        "id": "-ilpYnJ4m7FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AYzEcYubyGUY",
        "outputId": "76ab1f55-49e9-433f-ef56-6f2a4412feed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 28;\n",
              "                var nbb_unformatted_code = \"# Build the model\\nclass TransformerEncoder(layers.Layer):\\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\\n        super(TransformerEncoder, self).__init__(**kwargs)\\n        self.embed_dim = embed_dim\\n        self.dense_dim = dense_dim\\n        self.num_heads = num_heads\\n        self.attention = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.dense_proj = keras.Sequential(\\n            [layers.Dense(dense_dim, activation=\\\"relu\\\"), layers.Dense(embed_dim),]\\n        )\\n        self.layernorm_1 = layers.LayerNormalization()\\n        self.layernorm_2 = layers.LayerNormalization()\\n        self.supports_masking = True\\n\\n    def call(self, inputs, mask=None):\\n        if mask is not None:\\n            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\\\"int32\\\")\\n        attention_output = self.attention(\\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\\n        )\\n        proj_input = self.layernorm_1(inputs + attention_output)\\n        proj_output = self.dense_proj(proj_input)\\n        return self.layernorm_2(proj_input + proj_output)\\n\\n\\nclass PositionalEmbedding(layers.Layer):\\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\\n        super(PositionalEmbedding, self).__init__(**kwargs)\\n        self.token_embeddings = layers.Embedding(\\n            input_dim=vocab_size, output_dim=embed_dim\\n        )\\n        self.position_embeddings = layers.Embedding(\\n            input_dim=sequence_length, output_dim=embed_dim\\n        )\\n        self.sequence_length = sequence_length\\n        self.vocab_size = vocab_size\\n        self.embed_dim = embed_dim\\n\\n    def call(self, inputs):\\n        length = tf.shape(inputs)[-1]\\n        positions = tf.range(start=0, limit=length, delta=1)\\n        embedded_tokens = self.token_embeddings(inputs)\\n        embedded_positions = self.position_embeddings(positions)\\n        return embedded_tokens + embedded_positions\\n\\n    def compute_mask(self, inputs, mask=None):\\n        return tf.math.not_equal(inputs, 0)\\n\\n\\nclass TransformerDecoder(layers.Layer):\\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\\n        super(TransformerDecoder, self).__init__(**kwargs)\\n        self.embed_dim = embed_dim\\n        self.latent_dim = latent_dim\\n        self.num_heads = num_heads\\n        self.attention_1 = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.attention_2 = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.dense_proj = keras.Sequential(\\n            [layers.Dense(latent_dim, activation=\\\"relu\\\"), layers.Dense(embed_dim),]\\n        )\\n        self.layernorm_1 = layers.LayerNormalization()\\n        self.layernorm_2 = layers.LayerNormalization()\\n        self.layernorm_3 = layers.LayerNormalization()\\n        self.supports_masking = True\\n\\n    def call(self, inputs, encoder_outputs, mask=None):\\n        causal_mask = self.get_causal_attention_mask(inputs)\\n        if mask is not None:\\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\\\"int32\\\")\\n            padding_mask = tf.minimum(padding_mask, causal_mask)\\n\\n        attention_output_1 = self.attention_1(\\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\\n        )\\n        out_1 = self.layernorm_1(inputs + attention_output_1)\\n\\n        attention_output_2 = self.attention_2(\\n            query=out_1,\\n            value=encoder_outputs,\\n            key=encoder_outputs,\\n            attention_mask=padding_mask,\\n        )\\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\\n\\n        proj_output = self.dense_proj(out_2)\\n        return self.layernorm_3(out_2 + proj_output)\\n\\n    def get_causal_attention_mask(self, inputs):\\n        input_shape = tf.shape(inputs)\\n        batch_size, sequence_length = input_shape[0], input_shape[1]\\n        i = tf.range(sequence_length)[:, tf.newaxis]\\n        j = tf.range(sequence_length)\\n        mask = tf.cast(i >= j, dtype=\\\"int32\\\")\\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\\n        mult = tf.concat(\\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\\n            axis=0,\\n        )\\n        return tf.tile(mask, mult)\";\n",
              "                var nbb_formatted_code = \"# Build the model\\nclass TransformerEncoder(layers.Layer):\\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\\n        super(TransformerEncoder, self).__init__(**kwargs)\\n        self.embed_dim = embed_dim\\n        self.dense_dim = dense_dim\\n        self.num_heads = num_heads\\n        self.attention = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.dense_proj = keras.Sequential(\\n            [\\n                layers.Dense(dense_dim, activation=\\\"relu\\\"),\\n                layers.Dense(embed_dim),\\n            ]\\n        )\\n        self.layernorm_1 = layers.LayerNormalization()\\n        self.layernorm_2 = layers.LayerNormalization()\\n        self.supports_masking = True\\n\\n    def call(self, inputs, mask=None):\\n        if mask is not None:\\n            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\\\"int32\\\")\\n        attention_output = self.attention(\\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\\n        )\\n        proj_input = self.layernorm_1(inputs + attention_output)\\n        proj_output = self.dense_proj(proj_input)\\n        return self.layernorm_2(proj_input + proj_output)\\n\\n\\nclass PositionalEmbedding(layers.Layer):\\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\\n        super(PositionalEmbedding, self).__init__(**kwargs)\\n        self.token_embeddings = layers.Embedding(\\n            input_dim=vocab_size, output_dim=embed_dim\\n        )\\n        self.position_embeddings = layers.Embedding(\\n            input_dim=sequence_length, output_dim=embed_dim\\n        )\\n        self.sequence_length = sequence_length\\n        self.vocab_size = vocab_size\\n        self.embed_dim = embed_dim\\n\\n    def call(self, inputs):\\n        length = tf.shape(inputs)[-1]\\n        positions = tf.range(start=0, limit=length, delta=1)\\n        embedded_tokens = self.token_embeddings(inputs)\\n        embedded_positions = self.position_embeddings(positions)\\n        return embedded_tokens + embedded_positions\\n\\n    def compute_mask(self, inputs, mask=None):\\n        return tf.math.not_equal(inputs, 0)\\n\\n\\nclass TransformerDecoder(layers.Layer):\\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\\n        super(TransformerDecoder, self).__init__(**kwargs)\\n        self.embed_dim = embed_dim\\n        self.latent_dim = latent_dim\\n        self.num_heads = num_heads\\n        self.attention_1 = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.attention_2 = layers.MultiHeadAttention(\\n            num_heads=num_heads, key_dim=embed_dim\\n        )\\n        self.dense_proj = keras.Sequential(\\n            [\\n                layers.Dense(latent_dim, activation=\\\"relu\\\"),\\n                layers.Dense(embed_dim),\\n            ]\\n        )\\n        self.layernorm_1 = layers.LayerNormalization()\\n        self.layernorm_2 = layers.LayerNormalization()\\n        self.layernorm_3 = layers.LayerNormalization()\\n        self.supports_masking = True\\n\\n    def call(self, inputs, encoder_outputs, mask=None):\\n        causal_mask = self.get_causal_attention_mask(inputs)\\n        if mask is not None:\\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\\\"int32\\\")\\n            padding_mask = tf.minimum(padding_mask, causal_mask)\\n\\n        attention_output_1 = self.attention_1(\\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\\n        )\\n        out_1 = self.layernorm_1(inputs + attention_output_1)\\n\\n        attention_output_2 = self.attention_2(\\n            query=out_1,\\n            value=encoder_outputs,\\n            key=encoder_outputs,\\n            attention_mask=padding_mask,\\n        )\\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\\n\\n        proj_output = self.dense_proj(out_2)\\n        return self.layernorm_3(out_2 + proj_output)\\n\\n    def get_causal_attention_mask(self, inputs):\\n        input_shape = tf.shape(inputs)\\n        batch_size, sequence_length = input_shape[0], input_shape[1]\\n        i = tf.range(sequence_length)[:, tf.newaxis]\\n        j = tf.range(sequence_length)\\n        mask = tf.cast(i >= j, dtype=\\\"int32\\\")\\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\\n        mult = tf.concat(\\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\\n            axis=0,\\n        )\\n        return tf.tile(mask, mult)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WsKXYwLZ8HLl",
        "outputId": "6c15bf56-66a5-47a1-b3eb-227b5af9564b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 29;\n",
              "                var nbb_unformatted_code = \"embed_dim = 256\\nlatent_dim = 2048\\nnum_heads = 8\\n\\nencoder_inputs = keras.Input(shape=(None,), dtype=\\\"int64\\\", name=\\\"encoder_inputs\\\")\\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\\nencoder = keras.Model(encoder_inputs, encoder_outputs)\\n\\ndecoder_inputs = keras.Input(shape=(None,), dtype=\\\"int64\\\", name=\\\"decoder_inputs\\\")\\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\\\"decoder_state_inputs\\\")\\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\\nx = layers.Dropout(0.5)(x)\\ndecoder_outputs = layers.Dense(vocab_size, activation=\\\"softmax\\\")(x)\\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\\n\\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\\ntransformer = keras.Model(\\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\\\"transformer\\\"\\n)\";\n",
              "                var nbb_formatted_code = \"embed_dim = 256\\nlatent_dim = 2048\\nnum_heads = 8\\n\\nencoder_inputs = keras.Input(shape=(None,), dtype=\\\"int64\\\", name=\\\"encoder_inputs\\\")\\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\\nencoder = keras.Model(encoder_inputs, encoder_outputs)\\n\\ndecoder_inputs = keras.Input(shape=(None,), dtype=\\\"int64\\\", name=\\\"decoder_inputs\\\")\\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\\\"decoder_state_inputs\\\")\\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\\nx = layers.Dropout(0.5)(x)\\ndecoder_outputs = layers.Dense(vocab_size, activation=\\\"softmax\\\")(x)\\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\\n\\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\\ntransformer = keras.Model(\\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\\\"transformer\\\"\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "epochs = 60  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "# train the model \n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
        "# save model\n",
        "transformer.save(\"transformer_RNN_attribute_labels_class_weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7QR8b52jyI2y",
        "outputId": "d30ed458-9922-4f31-a3d7-fc6c34df4420"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "44/44 [==============================] - 21s 138ms/step - loss: 0.4598 - accuracy: 0.8209 - val_loss: 0.1484 - val_accuracy: 0.8408\n",
            "Epoch 2/60\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.1400 - accuracy: 0.8327 - val_loss: 0.1182 - val_accuracy: 0.8408\n",
            "Epoch 3/60\n",
            "44/44 [==============================] - 3s 73ms/step - loss: 0.1197 - accuracy: 0.8394 - val_loss: 0.1156 - val_accuracy: 0.8408\n",
            "Epoch 4/60\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.1211 - accuracy: 0.8384 - val_loss: 0.1148 - val_accuracy: 0.8408\n",
            "Epoch 5/60\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.1140 - accuracy: 0.8392 - val_loss: 0.1093 - val_accuracy: 0.8171\n",
            "Epoch 6/60\n",
            "44/44 [==============================] - 3s 71ms/step - loss: 0.1113 - accuracy: 0.8392 - val_loss: 0.1083 - val_accuracy: 0.8182\n",
            "Epoch 7/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.1058 - accuracy: 0.8429 - val_loss: 0.1040 - val_accuracy: 0.8441\n",
            "Epoch 8/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.1072 - accuracy: 0.8420 - val_loss: 0.1212 - val_accuracy: 0.8408\n",
            "Epoch 9/60\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.1054 - accuracy: 0.8452 - val_loss: 0.1004 - val_accuracy: 0.8508\n",
            "Epoch 10/60\n",
            "44/44 [==============================] - 3s 75ms/step - loss: 0.1019 - accuracy: 0.8499 - val_loss: 0.1015 - val_accuracy: 0.8414\n",
            "Epoch 11/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.1003 - accuracy: 0.8523 - val_loss: 0.0986 - val_accuracy: 0.8505\n",
            "Epoch 12/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0992 - accuracy: 0.8568 - val_loss: 0.0961 - val_accuracy: 0.8597\n",
            "Epoch 13/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0998 - accuracy: 0.8544 - val_loss: 0.0971 - val_accuracy: 0.8486\n",
            "Epoch 14/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0977 - accuracy: 0.8552 - val_loss: 0.0961 - val_accuracy: 0.8597\n",
            "Epoch 15/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.0984 - accuracy: 0.8579 - val_loss: 0.0959 - val_accuracy: 0.8597\n",
            "Epoch 16/60\n",
            "44/44 [==============================] - 3s 71ms/step - loss: 0.0987 - accuracy: 0.8527 - val_loss: 0.0957 - val_accuracy: 0.8597\n",
            "Epoch 17/60\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.0970 - accuracy: 0.8561 - val_loss: 0.0953 - val_accuracy: 0.8597\n",
            "Epoch 18/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.0967 - accuracy: 0.8550 - val_loss: 0.0953 - val_accuracy: 0.8610\n",
            "Epoch 19/60\n",
            "44/44 [==============================] - 3s 71ms/step - loss: 0.0966 - accuracy: 0.8573 - val_loss: 0.0956 - val_accuracy: 0.8610\n",
            "Epoch 20/60\n",
            "44/44 [==============================] - 3s 70ms/step - loss: 0.0965 - accuracy: 0.8555 - val_loss: 0.0952 - val_accuracy: 0.8610\n",
            "Epoch 21/60\n",
            "44/44 [==============================] - 3s 74ms/step - loss: 0.0961 - accuracy: 0.8547 - val_loss: 0.0945 - val_accuracy: 0.8610\n",
            "Epoch 22/60\n",
            "44/44 [==============================] - 3s 73ms/step - loss: 0.0956 - accuracy: 0.8574 - val_loss: 0.0943 - val_accuracy: 0.8610\n",
            "Epoch 23/60\n",
            "44/44 [==============================] - 3s 72ms/step - loss: 0.0958 - accuracy: 0.8551 - val_loss: 0.0937 - val_accuracy: 0.8608\n",
            "Epoch 24/60\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0949 - accuracy: 0.8581 - val_loss: 0.0938 - val_accuracy: 0.8602\n",
            "Epoch 25/60\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.0953 - accuracy: 0.8559 - val_loss: 0.0934 - val_accuracy: 0.8600\n",
            "Epoch 26/60\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.0952 - accuracy: 0.8564 - val_loss: 0.0944 - val_accuracy: 0.8610\n",
            "Epoch 27/60\n",
            "44/44 [==============================] - 3s 71ms/step - loss: 0.0951 - accuracy: 0.8559 - val_loss: 0.0945 - val_accuracy: 0.8591\n",
            "Epoch 28/60\n",
            "44/44 [==============================] - 3s 73ms/step - loss: 0.0945 - accuracy: 0.8586 - val_loss: 0.0947 - val_accuracy: 0.8521\n",
            "Epoch 29/60\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.0948 - accuracy: 0.8571 - val_loss: 0.0937 - val_accuracy: 0.8548\n",
            "Epoch 30/60\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.0943 - accuracy: 0.8566 - val_loss: 0.0941 - val_accuracy: 0.8529\n",
            "Epoch 31/60\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.0948 - accuracy: 0.8560 - val_loss: 0.0936 - val_accuracy: 0.8556\n",
            "Epoch 32/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0948 - accuracy: 0.8541 - val_loss: 0.0939 - val_accuracy: 0.8573\n",
            "Epoch 33/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.0945 - accuracy: 0.8576 - val_loss: 0.0939 - val_accuracy: 0.8573\n",
            "Epoch 34/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0945 - accuracy: 0.8583 - val_loss: 0.0941 - val_accuracy: 0.8578\n",
            "Epoch 35/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0945 - accuracy: 0.8584 - val_loss: 0.0936 - val_accuracy: 0.8548\n",
            "Epoch 36/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0939 - accuracy: 0.8572 - val_loss: 0.0938 - val_accuracy: 0.8573\n",
            "Epoch 37/60\n",
            "44/44 [==============================] - 3s 74ms/step - loss: 0.0940 - accuracy: 0.8572 - val_loss: 0.0939 - val_accuracy: 0.8554\n",
            "Epoch 38/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0961 - accuracy: 0.8550 - val_loss: 0.0934 - val_accuracy: 0.8578\n",
            "Epoch 39/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0953 - accuracy: 0.8554 - val_loss: 0.0933 - val_accuracy: 0.8600\n",
            "Epoch 40/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0944 - accuracy: 0.8560 - val_loss: 0.0928 - val_accuracy: 0.8605\n",
            "Epoch 41/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0939 - accuracy: 0.8584 - val_loss: 0.0931 - val_accuracy: 0.8589\n",
            "Epoch 42/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0940 - accuracy: 0.8584 - val_loss: 0.0939 - val_accuracy: 0.8540\n",
            "Epoch 43/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0942 - accuracy: 0.8584 - val_loss: 0.0933 - val_accuracy: 0.8551\n",
            "Epoch 44/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0935 - accuracy: 0.8583 - val_loss: 0.0931 - val_accuracy: 0.8581\n",
            "Epoch 45/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0948 - accuracy: 0.8579 - val_loss: 0.0931 - val_accuracy: 0.8600\n",
            "Epoch 46/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0936 - accuracy: 0.8586 - val_loss: 0.0931 - val_accuracy: 0.8613\n",
            "Epoch 47/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0942 - accuracy: 0.8552 - val_loss: 0.0931 - val_accuracy: 0.8602\n",
            "Epoch 48/60\n",
            "44/44 [==============================] - 3s 71ms/step - loss: 0.0936 - accuracy: 0.8572 - val_loss: 0.0933 - val_accuracy: 0.8597\n",
            "Epoch 49/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0942 - accuracy: 0.8575 - val_loss: 0.0932 - val_accuracy: 0.8608\n",
            "Epoch 50/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0938 - accuracy: 0.8590 - val_loss: 0.0936 - val_accuracy: 0.8567\n",
            "Epoch 51/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0936 - accuracy: 0.8598 - val_loss: 0.0934 - val_accuracy: 0.8581\n",
            "Epoch 52/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0932 - accuracy: 0.8594 - val_loss: 0.0932 - val_accuracy: 0.8583\n",
            "Epoch 53/60\n",
            "44/44 [==============================] - 3s 75ms/step - loss: 0.0935 - accuracy: 0.8571 - val_loss: 0.0930 - val_accuracy: 0.8591\n",
            "Epoch 54/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0939 - accuracy: 0.8575 - val_loss: 0.0929 - val_accuracy: 0.8586\n",
            "Epoch 55/60\n",
            "44/44 [==============================] - 3s 72ms/step - loss: 0.0930 - accuracy: 0.8600 - val_loss: 0.0932 - val_accuracy: 0.8583\n",
            "Epoch 56/60\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.0932 - accuracy: 0.8588 - val_loss: 0.0944 - val_accuracy: 0.8565\n",
            "Epoch 57/60\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.0933 - accuracy: 0.8600 - val_loss: 0.0930 - val_accuracy: 0.8581\n",
            "Epoch 58/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0934 - accuracy: 0.8581 - val_loss: 0.0934 - val_accuracy: 0.8565\n",
            "Epoch 59/60\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0934 - accuracy: 0.8591 - val_loss: 0.0933 - val_accuracy: 0.8581\n",
            "Epoch 60/60\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.0931 - accuracy: 0.8604 - val_loss: 0.0933 - val_accuracy: 0.8562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_RNN_attribute_labels_class_weights/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_RNN_attribute_labels_class_weights/assets\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 30;\n",
              "                var nbb_unformatted_code = \"# Compile the model\\nepochs = 60  # This should be at least 30 for convergence\\n\\ntransformer.summary()\\ntransformer.compile(\\n    \\\"rmsprop\\\", loss=\\\"sparse_categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"]\\n)\\n# train the model \\ntransformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\\n# save model\\ntransformer.save(\\\"transformer_RNN_attribute_labels_class_weights\\\")\";\n",
              "                var nbb_formatted_code = \"# Compile the model\\nepochs = 60  # This should be at least 30 for convergence\\n\\ntransformer.summary()\\ntransformer.compile(\\n    \\\"rmsprop\\\", loss=\\\"sparse_categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"]\\n)\\n# train the model\\ntransformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\\n# save model\\ntransformer.save(\\\"transformer_RNN_attribute_labels_class_weights\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fv8uw62SnWwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='TP'></a>\n",
        "## [Test Data Performance](#P0)"
      ],
      "metadata": {
        "id": "OB0RGOmRMUCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "busi_vocab = busi_vectorization.get_vocabulary()\n",
        "busi_index_lookup = dict(zip(range(len(busi_vocab)), busi_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = tech_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = busi_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = busi_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_tech_texts = [pair[0] for pair in val_pairs]\n",
        "for _ in range(len(test_pairs)):\n",
        "    input_sentence = np.random.choice(test_tech_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ORbuz331yM-k",
        "outputId": "778e5246-ca0b-4004-cc14-1031d3e71438"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK]  [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]    [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n",
            "[start] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]  [UNK] \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 31;\n",
              "                var nbb_unformatted_code = \"busi_vocab = busi_vectorization.get_vocabulary()\\nbusi_index_lookup = dict(zip(range(len(busi_vocab)), busi_vocab))\\nmax_decoded_sentence_length = 20\\n\\n\\ndef decode_sequence(input_sentence):\\n    tokenized_input_sentence = tech_vectorization([input_sentence])\\n    decoded_sentence = \\\"[start]\\\"\\n    for i in range(max_decoded_sentence_length):\\n        tokenized_target_sentence = busi_vectorization([decoded_sentence])[:, :-1]\\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\\n\\n        sampled_token_index = np.argmax(predictions[0, i, :])\\n        sampled_token = busi_index_lookup[sampled_token_index]\\n        decoded_sentence += \\\" \\\" + sampled_token\\n\\n        if sampled_token == \\\"[end]\\\":\\n            break\\n    return decoded_sentence\\n\\n\\ntest_tech_texts = [pair[0] for pair in val_pairs]\\nfor _ in range(len(test_pairs)):\\n    input_sentence = np.random.choice(test_tech_texts)\\n    translated = decode_sequence(input_sentence)\\n    print(translated)\";\n",
              "                var nbb_formatted_code = \"busi_vocab = busi_vectorization.get_vocabulary()\\nbusi_index_lookup = dict(zip(range(len(busi_vocab)), busi_vocab))\\nmax_decoded_sentence_length = 20\\n\\n\\ndef decode_sequence(input_sentence):\\n    tokenized_input_sentence = tech_vectorization([input_sentence])\\n    decoded_sentence = \\\"[start]\\\"\\n    for i in range(max_decoded_sentence_length):\\n        tokenized_target_sentence = busi_vectorization([decoded_sentence])[:, :-1]\\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\\n\\n        sampled_token_index = np.argmax(predictions[0, i, :])\\n        sampled_token = busi_index_lookup[sampled_token_index]\\n        decoded_sentence += \\\" \\\" + sampled_token\\n\\n        if sampled_token == \\\"[end]\\\":\\n            break\\n    return decoded_sentence\\n\\n\\ntest_tech_texts = [pair[0] for pair in val_pairs]\\nfor _ in range(len(test_pairs)):\\n    input_sentence = np.random.choice(test_tech_texts)\\n    translated = decode_sequence(input_sentence)\\n    print(translated)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OJWUdE90cUKZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "CA0lXBcZYnFu"
      },
      "source": [
        "<a id='CL'></a>\n",
        "## [Conclusion](#P0)\n",
        "\n",
        "Although the model has acceptablee Accuracy of .86, the predicions made on the test data set by the model are all unclear. Thus, this model is unable to generate any useful translations of the Technical Names into the Attribute Business Names. \n",
        "\n",
        "In Sum, the character-level Sequence to Sequence Model is the best performing nlp model for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC2g6fGxYnFu"
      },
      "source": [
        "<div style=\"border-top:0.1cm solid #EF475B\"></div>\n",
        "    <strong><a href='#Q0'><div style=\"text-align: right\"> <h3>End of this Notebook.</h3></div></a></strong>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Sidecar_Project_Word-level_seq2seq_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}